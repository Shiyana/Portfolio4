<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Artifact 4: Clustering Analysis with K-Means</title>
  <style>
    body { font-family: Arial, sans-serif; background-color: #f4f8fb; color: #333; margin: 0; padding: 0; }
    header, footer { background-color: #1e3799; color: white; text-align: center; padding: 20px; }
    .container { max-width: 1000px; margin: 20px auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
    h1, h2, h3 { color: #1e3799; }
    .tabs { display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 20px; }
    .tabs button { background: #1e3799; color: white; border: none; padding: 10px 15px; border-radius: 5px; cursor: pointer; }
    .tabs button:hover { background: #60a3bc; }
    .tab-content { display: none; }
    .tab-content.active { display: block; }
    .charts img { max-width: 90%; margin: 10px auto; display: block; border: 1px solid #ccc; border-radius: 5px; }
    a { color: #ffffff; text-decoration: underline; }
    pre.code { background: #f0f0f0; padding: 10px; border-radius: 4px; overflow-x: auto; }
    ul li { margin-bottom: 10px; }
  </style>
  <script>
    function showTab(id) {
      document.querySelectorAll('.tab-content').forEach(tab => tab.classList.remove('active'));
      document.getElementById(id).classList.add('active');
    }
    document.addEventListener('DOMContentLoaded', () => {
      showTab('overview');
    });
  </script>
</head>
<body>
  <header>
    <h1>Artifact 4: Clustering Analysis with K-Means</h1>
    <p>Shiyana Jayanesan Shylaja | Machine Learning Portfolio</p>
  </header>

  <div class="container">
    <div class="tabs">
      <button onclick="showTab('overview')">Overview</button>
      <button onclick="showTab('process')">Process</button>
      <button onclick="showTab('challenges')">Challenges</button>
      <button onclick="showTab('takeaways')">Key Takeaways</button>
      <button onclick="showTab('reflection')">Reflection</button>
      <button onclick="showTab('conclusion')">Conclusion</button>
    </div>

    <div class="tab-content" id="overview">
      <h2>Overview</h2>
      <p>This project stems from our practical exploration of unsupervised learning, specifically using K-Means clustering to identify hidden patterns in customer behavioral data. As part of our Machine Learning Fundamentals course, we engaged with multiple real-world datasets and simulated scenarios that focused on data challenges such as missing entries, noisy features, and highly imbalanced classes.</p>
      <p>Three major scenarios shaped this artifact:</p>
      <ol>
        <li><strong>Scenario 1 - Missing Data:</strong> We worked with a health dataset that had 15–20% missing entries across several attributes. I employed mean, median, and KNN-based imputation techniques and validated results using visual inspection and statistical summaries.</li>
        <li><strong>Scenario 2 - Noisy Data:</strong> In a sensor data simulation, random spikes distorted the readings. I applied moving averages, Gaussian smoothing, and median filters to reduce volatility without distorting the overall trend.</li>
        <li><strong>Scenario 3 - Class Imbalance:</strong> For disease classification, only 8% of the data reflected positive cases. I compared over-sampling (SMOTE), under-sampling, and ensemble models with class-weight adjustments to address this issue.</li>
      </ol>
      <p>This artifact integrates the learnings from these experiences and applies them to clustering a customer segmentation dataset. The objective was to group customers based on attributes like income and spending behavior. The final deliverable was a fully visualized model, validated with appropriate cluster evaluation metrics.</p>
      <img src="overview-diagram.png" alt="Overview Diagram">
    </div>

    <div class="tab-content" id="process">
      <h2>Process</h2>
      <p>This tab breaks down the detailed process undertaken during the clustering exercise:</p>
      <h3>1. Data Loading and Cleaning</h3>
      <ul>
        <li>Imported dataset with features such as Age, Income, Spending Score.</li>
        <li>Checked null values and removed/treated them using KNN Imputer.</li>
        <li>Applied normalization (StandardScaler) to bring all features to the same scale.</li>
      </ul>
      <h3>2. Feature Engineering</h3>
      <ul>
        <li>Derived "Spending per Income" ratio to better capture relative behavior.</li>
        <li>Used correlation matrix to drop redundant features.</li>
      </ul>
      <h3>3. Dimensionality Reduction</h3>
      <ul>
        <li>Used PCA to reduce the dataset to 2 principal components for visual clustering.</li>
        <li>Eliminated noise using variance thresholding techniques.</li>
      </ul>
      <h3>4. Cluster Evaluation</h3>
      <ul>
        <li>Ran KMeans with varying k (2 to 10) and used Elbow and Silhouette methods to finalize k=3.</li>
        <li>Validated cluster stability with multiple initialization seeds.</li>
      </ul>
      <h3>5. Visualization</h3>
      <ul>
        <li>Created scatterplots with seaborn and matplotlib for PCA and t-SNE visualizations.</li>
        <li>Color-coded cluster memberships and included centroids for interpretation.</li>
      </ul>
      <div class="charts">
        <img src="elbow-method.png" alt="Elbow Method Chart">
        <img src="silhouette.png" alt="Silhouette Score Chart">
        <img src="clusters.png" alt="Cluster Visualization">
      </div>
      <pre class="code">
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
data_scaled = scaler.fit_transform(df)

kmeans = KMeans(n_clusters=3, random_state=0)
kmeans.fit(data_scaled)
df['Cluster'] = kmeans.labels_
      </pre>
    </div>

    <div class="tab-content" id="challenges">
      <h2>Challenges & Solutions</h2>
      <ul>
        <li><strong>High Dimensionality:</strong> Handled by applying PCA to reduce complexity and visualize effectively.</li>
        <li><strong>Noise Interference:</strong> Used statistical techniques (rolling mean, median filtering) to reduce random spikes.</li>
        <li><strong>Overfitting from Imbalanced Data:</strong> Controlled with synthetic data generation (SMOTE) and adjusted model weights.</li>
        <li><strong>Interpretability:</strong> Introduced SHAP plots and centroid comparison to help non-technical stakeholders understand cluster characteristics.</li>
        <li><strong>Ethical Concerns:</strong> Regular bias audits ensured clusters did not disproportionately represent sensitive groups unfairly.</li>
      </ul>
    </div>

    <div class="tab-content" id="takeaways">
      <h2>Key Takeaways</h2>
      <ul>
        <li>Scenario-based learning improves long-term retention of data science problem-solving strategies.</li>
        <li>KMeans, while powerful, works best when clusters are spherical and equidistant—highlighting the importance of choosing the right model.</li>
        <li>Combining dimensionality reduction with clustering offers significant gains in interpretability and performance.</li>
        <li>Class activities focusing on human bias and leadership helped me reflect on the ethical application of AI in real-world education and healthcare systems.</li>
        <li>Effective communication—both visual (charts) and narrative (explanations)—plays a vital role in the lifecycle of AI solutions.</li>
      </ul>
    </div>

    <div class="tab-content" id="reflection">
      <h2>Reflection</h2>
      <p>This assignment challenged me to think like a practitioner and an ethical leader simultaneously. The technical skills I developed in unsupervised learning were complemented by reflective activities that made me assess AI’s role in human-centric domains like education. I realized that building a working model is only part of the solution—how that model impacts people matters equally. I’ve grown more comfortable navigating technical ambiguity and making decisions that align with ethical values.</p>
      <p>The combination of data challenges, such as missing data and noise, prepared me for the types of issues that appear in the real world. Additionally, participating in discussions on human bias and AI leadership made me more aware of systemic risks and how to build inclusive technologies.</p>
    </div>

    <div class="tab-content" id="conclusion">
      <h2>Conclusion & Future Directions</h2>
      <ul>
        <li>Extend current project using DBSCAN and Agglomerative clustering to evaluate performance in non-spherical datasets.</li>
        <li>Build a modular dashboard to let users interactively explore cluster segments using Plotly Dash.</li>
        <li>Incorporate explainable AI tools like LIME for cluster profiling and interpretability.</li>
        <li>Apply clustering to real student datasets to develop adaptive education recommendations.</li>
        <li>Submit this project for peer review or integrate into my GitHub repository to showcase AI proficiency.</li>
      </ul>
    </div>
  </div>

  <footer>
    <p>&copy; 2025 Shiyana Jayanesan Shylaja |
      <a href="https://sites.google.com/view/shiyana-portfolio/home" target="_blank">Artifact 1</a> |
      <a href="https://shiyana.github.io/Portfolio2/" target="_blank">Artifact 2</a> |
      <a href="https://shiyana.github.io/Portfolio3/" target="_blank">Artifact 3</a> |
      <a href="https://shiyana.github.io/Portfolio4/">Artifact 4</a>
    </p>
  </footer>
</body>
</html>
