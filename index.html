<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Artifact 4: K-Means Clustering</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f8f9fa;
      color: #212529;
      margin: 0;
      padding: 0;
    }
    header, footer {
      background-color: #003366;
      color: white;
      text-align: center;
      padding: 20px;
    }
    .tabs {
      display: flex;
      flex-wrap: wrap;
      background-color: #e3eaf2;
      padding: 10px 20px;
      gap: 10px;
      justify-content: center;
    }
    .tabs button {
      background-color: #005792;
      color: white;
      border: none;
      padding: 10px 16px;
      border-radius: 5px;
      cursor: pointer;
    }
    .tabs button:hover {
      background-color: #0074c7;
    }
    .tab-content {
      display: none;
      padding: 30px;
      max-width: 1200px;
      margin: auto;
      background-color: white;
    }
    .tab-content.active {
      display: block;
    }
    h2 {
      color: #005792;
    }
    ul {
      line-height: 1.8;
      margin-left: 20px;
    }
    .diagram {
      text-align: center;
      margin-top: 30px;
    }
    .diagram img {
      width: 90%;
      max-width: 800px;
      border: 1px solid #ccc;
      border-radius: 10px;
    }
    a {
      color: #ffffff;
      text-decoration: underline;
    }
  </style>
  <script>
    function showTab(id) {
      document.querySelectorAll('.tab-content').forEach(tab => tab.classList.remove('active'));
      document.getElementById(id).classList.add('active');
    }
    document.addEventListener('DOMContentLoaded', () => {
      showTab('overview');
    });
  </script>
</head>
<body>
  <header>
    <h1>Artifact 4: K-Means Clustering on Retail Customers</h1>
    <p>Shiyana Jayanesan Shylaja | Machine Learning Portfolio</p>
  </header>

  <div class="tabs">
    <button onclick="showTab('overview')">Overview</button>
    <button onclick="showTab('process')">Process</button>
    <button onclick="showTab('challenges')">Challenges</button>
    <button onclick="showTab('takeaways')">Key Takeaways</button>
    <button onclick="showTab('reflection')">Reflection</button>
    <button onclick="showTab('conclusion')">Conclusion</button>
  </div>

  <div class="tab-content active" id="overview">
    <h2>Overview</h2>
    <p><strong>Objective:</strong> The goal of this project was to apply the K-Means clustering algorithm on a retail customer dataset to segment customers for personalized marketing strategies. Through the integration of ethical principles and human-centered AI practices, I aimed to reflect the values discussed during class activities, especially in handling real-world data challenges.</p>

    <h3>Key Scenario Activities</h3>
    <ul>
      <li><strong>Scenario 1 - Missing Data:</strong> Simulated a health dataset with missing age/weight. Applied median and multiple imputations. Discussed ethical risks of ignoring underrepresented demographics.</li>
      <li><strong>Scenario 2 - Noisy Data:</strong> Evaluated sensor data with irregular spikes. Applied smoothing techniques like moving average. Discussed the importance of transparent preprocessing.</li>
      <li><strong>Scenario 3 - Imbalanced Dataset:</strong> Handled rare disease classification where only a few cases existed. Used SMOTE and class weighting. Discussed inclusion and fairness.</li>
    </ul>

    <h3>Impact of Class Activity</h3>
    <p>These scenarios taught me to view preprocessing as not just a technical requirement, but a leadership opportunity—building models that are accurate, transparent, and inclusive. I implemented clustering while maintaining this ethical perspective.</p>

    <div class="diagram">
      <h3>Overview Flowchart: Project Structure</h3>
      <img src="https://raw.githubusercontent.com/shiyana/Portfolio4/main/overview-flowchart.png" alt="Overview Diagram">
      <p><em>Figure: End-to-end pipeline from data collection to ethical interpretation</em></p>
    </div>
  </div>
  <div class="tab-content" id="process">
    <h2>Process</h2>

    <h3>1. Data Collection and Initial Exploration</h3>
    <ul>
      <li>Sourced a retail dataset (e.g., Mall_Customers.csv) containing Age, Gender, Annual Income, and Spending Score.</li>
      <li>Initial exploration showed 5% missing values in income and 3% in age fields.</li>
      <li>Outliers identified using Z-score thresholding (> 3).</li>
      <li>Used Seaborn heatmaps to visualize missingness across features.</li>
    </ul>

    <h3>2. Handling Missing Data (Scenario 1)</h3>
    <ul>
      <li>Used <code>SimpleImputer(strategy='median')</code> for numerical features to preserve central tendency.</li>
      <li>Also tried MICE (Multiple Imputation by Chained Equations) to evaluate robustness.</li>
      <li>Ensured fairness by analyzing distribution of imputed values across gender and age buckets.</li>
    </ul>

    <h4>Python Snippet:</h4>
    <pre><code>from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='median')
df['Income'] = imputer.fit_transform(df[['Income']])</code></pre>

    <h3>3. Data Smoothing and Cleaning (Scenario 2)</h3>
    <ul>
      <li>Used moving average (window = 3) to smooth out spending fluctuations.</li>
      <li>Filtered anomalies (e.g., incomes > $300,000) using Z-score filters.</li>
      <li>Retained sufficient variability to preserve cluster integrity.</li>
    </ul>

    <h4>Python Snippet:</h4>
    <pre><code>df['Spending_Score_Smoothed'] = df['Spending_Score'].rolling(3).mean()</code></pre>

    <h3>4. Feature Engineering</h3>
    <ul>
      <li>Created "Income per Age" feature to improve clustering signal.</li>
      <li>Normalized variables using <code>StandardScaler</code> to eliminate scale bias.</li>
      <li>Performed PCA for dimensionality reduction — retained 2 principal components.</li>
    </ul>

    <h3>5. Choosing K (Number of Clusters)</h3>
    <ul>
      <li>Used the Elbow Method and Silhouette Scores to determine optimal k = 4.</li>
      <li>Plotted inertia values from k=1 to k=10 to identify elbow point.</li>
    </ul>

    <div class="diagram">
      <img src="https://raw.githubusercontent.com/shiyana/Portfolio4/main/elbow-method.png" alt="Elbow Method Chart">
      <p><em>Figure: Elbow Method to determine optimal number of clusters (k=4)</em></p>
    </div>

    <h3>6. K-Means Implementation</h3>
    <ul>
      <li>Used <code>sklearn.cluster.KMeans</code> with k=4 and <code>random_state=42</code> for reproducibility.</li>
      <li>Clusters labeled based on average income and spending score characteristics.</li>
    </ul>

    <h4>Python Snippet:</h4>
    <pre><code>from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=4, random_state=42)
df['Cluster'] = kmeans.fit_predict(df[['Income', 'Spending_Score']])</code></pre>

    <h3>7. Addressing Imbalance (Scenario 3)</h3>
    <ul>
      <li>Applied SMOTE (Synthetic Minority Over-sampling Technique) to simulate balanced segments in a mock supervised task.</li>
      <li>Compared cluster distributions pre- and post-SMOTE to check model drift.</li>
      <li>Evaluated fairness with disaggregated performance metrics by group.</li>
    </ul>

    <h4>Python Snippet:</h4>
    <pre><code>from imblearn.over_sampling import SMOTE
X_resampled, y_resampled = SMOTE().fit_resample(X, y)</code></pre>

    <h3>8. Visualization of Clusters</h3>
    <div class="diagram">
      <img src="https://raw.githubusercontent.com/shiyana/Portfolio4/main/kmeans-clusters.png" alt="Cluster Visualization">
      <p><em>Figure: 2D scatter plot of customer clusters with k=4</em></p>
    </div>

    <h3>Summary</h3>
    <ul>
      <li>From raw data to validated clustering, each step emphasized transparency and fairness.</li>
      <li>Scenario-based learning shaped technical decisions and stakeholder communication practices.</li>
    </ul>
  </div>
  <div class="tab-content" id="challenges">
    <h2>Challenges</h2>

    <h3>1. Balancing Imputation Accuracy with Fairness</h3>
    <ul>
      <li>Imputing missing values introduced risks of reinforcing central bias, particularly with underrepresented demographic groups.</li>
      <li>To mitigate this, we compared results from median, mean, and MICE strategies and cross-checked value distributions by race and gender.</li>
      <li>Challenge: median imputation favored central income brackets, risking the erasure of outliers with valid socioeconomic meaning.</li>
      <li>Solution: Introduced missingness indicators (Boolean flags) to preserve signal and perform post-hoc bias checks.</li>
    </ul>

    <h3>2. Outlier Treatment without Distortion</h3>
    <ul>
      <li>Removing outliers could distort segmentation logic if anomalies carried meaning (e.g., high-income spenders).</li>
      <li>Applied Z-score filters cautiously, and used IQR (Interquartile Range) as a secondary check.</li>
      <li>Visual inspection through boxplots was essential in deciding what to retain or exclude.</li>
    </ul>

    <h3>3. Interpretation of Clusters for Stakeholders</h3>
    <ul>
      <li>Explaining K-Means clusters to non-technical audiences proved challenging—e.g., defining why cluster 2 had high spending scores but low income.</li>
      <li>Translated clusters into customer personas: “Budget-Conscious Spenders,” “Affluent Explorers,” “High Earners, Low Spenders,” etc.</li>
      <li>Used visual aids and comparative bar graphs to improve understanding.</li>
    </ul>

    <h3>4. Technical Tradeoffs Between k and Interpretability</h3>
    <ul>
      <li>Increasing k from 3 to 5 improved silhouette scores but diluted practical meaning of clusters.</li>
      <li>Final k=4 chosen for optimal tradeoff between granularity and stakeholder relevance.</li>
      <li>Required iterative experimentation with <code>n_init</code> and <code>max_iter</code> to ensure convergence stability.</li>
    </ul>

    <h3>5. Time Constraints and Integration</h3>
    <ul>
      <li>Running multiple scenarios (missing, noise, imbalance) with consistent documentation under limited project timelines was a major challenge.</li>
      <li>Developed Jupyter notebooks for each phase, automated graph generation, and created markdown summaries for integration into this portfolio.</li>
    </ul>

    <h3>6. Navigating Ethical Ambiguities</h3>
    <ul>
      <li>How should clusters be used in real marketing? Could they reinforce stereotypes?</li>
      <li>Inspired by “Navigating Human Bias” class activity, I reviewed fairness metrics before finalizing deployment recommendations.</li>
      <li>Integrated optional feedback loops into the reporting structure (e.g., customer satisfaction by cluster) to iterate ethically.</li>
    </ul>

    <div class="diagram">
      <img src="https://raw.githubusercontent.com/shiyana/Portfolio4/main/challenges-diagram.png" alt="Challenges Visual Breakdown" />
      <p><em>Figure: Summary flow showing preprocessing issues, mitigation strategies, and fairness reviews</em></p>
    </div>
  </div>
