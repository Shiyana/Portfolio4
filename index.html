from pathlib import Path

# Full HTML content with updated sections
full_html_code = """
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Artifact 4: Clustering Analysis with K-Means</title>
  <style>
    body { font-family: Arial, sans-serif; background-color: #f4f8fb; color: #333; margin: 0; padding: 0; }
    header, footer { background-color: #1e3799; color: white; text-align: center; padding: 10px; } /* Reduced padding for compact header */
    header h1 { font-size: 1.5em; margin: 0; } /* Reduced font size for compactness */
    header p { font-size: 0.9em; margin: 0; } /* Adjusted font size for subtitle */
    .container { max-width: 1000px; margin: 20px auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
    h1, h2, h3 { color: #1e3799; }
    .tabs { display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 20px; }
    .tabs button { background: #1e3799; color: white; border: none; padding: 10px 15px; border-radius: 5px; cursor: pointer; }
    .tabs button:hover { background: #60a3bc; }
    .tab-content { display: none; }
    .tab-content.active { display: block; }
    .charts img { max-width: 50%; margin: 10px auto; display: block; border: 1px solid #ccc; border-radius: 5px; } /* Medium size for diagrams */
    a { color: #ffffff; text-decoration: underline; }
    ul { margin-left: 20px; }
    svg { max-width: 50%; height: auto; } /* Medium size for SVG if used */
  </style>
  <script>
    function showTab(id) {
      document.querySelectorAll('.tab-content').forEach(tab => tab.classList.remove('active'));
      document.getElementById(id).classList.add('active');
    }
    document.addEventListener('DOMContentLoaded', () => {
      showTab('overview');
    });
  </script>
</head>
<body>
  <header>
    <h1>Artifact 4: Clustering Analysis with K-Means</h1>
    <p>Shiyana Jayanesan Shylaja | Machine Learning Portfolio 4</p>
  </header>

  <div class="container">
    <div class="tabs">
      <button onclick="showTab('overview')">Overview</button>
      <button onclick="showTab('process')">Process</button>
      <button onclick="showTab('challenges')">Challenges</button>
      <button onclick="showTab('takeaways')">Key Takeaways</button>
      <button onclick="showTab('reflection')">Reflection</button>
      <button onclick="showTab('conclusion')">Conclusion</button>
    </div>

    <div class="tab-content" id="overview">
      <h2>Overview</h2>
      <p>
        This artifact applies unsupervised learning through K-Means clustering to segment a retail customer dataset based on income and spending scores, facilitating targeted marketing strategies. Influenced by the "Navigating Human Bias as a Leader in AI and Education" class activity, I prioritized ethical leadership and fairness, exploring real-world data challenges through a structured chatbot-guided exercise. The exercise comprised three detailed scenarios:
        <ul class="list-disc ml-6 mt-2">
          <li><strong>Scenario 1: Missing Data</strong> - Addressed incomplete health study data (e.g., missing age and weight) using median imputation and multiple imputation with IterativeImputer from Scikit-learn. Analyzed how missingness could bias results for underrepresented groups like low-income patients, a concern echoed in healthcare AI audits, and implemented missingness flags to track impacts.</li>
          <li><strong>Scenario 2: Noisy Data</strong> - Involved noisy sensor readings smoothed with moving averages and z-score filtering, assessing how noise might distort fair customer segmentation in e-commerce analytics. Explored the trade-off between data smoothing and retaining meaningful variability.</li>
          <li><strong>Scenario 3: Imbalanced Datasets</strong> - Applied SMOTE and class weighting to predict rare diseases, ensuring models didn’t overlook minority populations, a practice relevant to inclusive marketing campaigns. Evaluated synthetic sample generation’s effect on model performance.</li>
        </ul>
        These scenarios, executed with Python (e.g., pandas, Scikit-learn), enhanced my technical and ethical proficiency. Visual aids, such as the overview diagram, illustrate the workflow and segmentation outcomes.
      </p>
      <div class="mt-4">
        <h3>Overview Diagram</h3>
        <img src="overview-diagram.png" alt="Overview Diagram of Clustering Process" />
      </div>
    </div>

    <div class="tab-content" id="process">
      <h2>Process</h2>
      <p>
        <div class="space-y-6">
          <div>
            <h3>Data Collection and Assessment</h3>
            <p>Collected a retail dataset with 2000 entries, including annual income, spending score, and age. Used pandas to detect 5% missing values and outliers (z-score > 3), visualized with Seaborn heatmaps to identify correlations between features.</p>
          </div>
          <div>
            <h3>Handling Missing Data</h3>
            <p>Applied median imputation for income and multiple imputation (MICE) for cross-validation, adding missingness flags to track potential bias. This ensured fair representation across income groups, validated through statistical tests.</p>
          </div>
          <div>
            <h3>Data Cleaning</h3>
            <p>Employed a 3-point rolling average and z-score filtering to smooth spending score anomalies, removing outliers (e.g., incomes > $500,000). Validated the process with pre- and post-cleaning statistical summaries.</p>
          </div>
          <div>
            <h3>Clustering Implementation</h3>
            <p>Determined k=4 clusters using the elbow method and silhouette scores with Scikit-learn’s KMeans. Refined assignments based on business needs, such as targeting high-spending segments.</p>
            <div class="charts">
              <img src="elbow-method.png" alt="Elbow Method Graph for Optimal Cluster Selection" />
            </div>
          </div>
          <div>
            <h3>Exploration of Imbalance</h3>
            <p>Tested SMOTE to synthesize samples and class weights for a mock supervised model, ensuring fair representation of minority customer groups. Evaluated outcomes against business goals.</p>
            <div class="charts">
              <img src="clusters.png" alt="Visualization of Customer Clusters" />
            </div>
          </div>
        </div>
      </p>
    </div>

    <div class="tab-content" id="challenges">
      <h2>Challenges</h2>
      <p>
        <ul class="list-disc ml-6 space-y-2">
          <li>Balancing imputation accuracy with fairness required iterative testing, as median imputation risked skewing income data for underrepresented groups like rural customers, a issue I tackled during daily dataset reviews.</li>
          <li>Smoothing outliers threatened to erase valuable spending patterns, necessitating careful tuning during evening sessions, similar to challenges faced in real-time stock market data analysis.</li>
          <li>Ensuring ethical segmentation demanded constant bias checks, a weekly hurdle during peer reviews, mirroring efforts in facial recognition systems to avoid demographic biases.</li>
          <li>Time management was strained, as balancing morning client meetings, afternoon coding, and this artifact forced prioritization, akin to project deadlines in tech startups.</li>
          <li>Explaining cluster results to non-technical stakeholders, like family, required simplifying ethical implications, a skill tested during discussions about AI in healthcare.</li>
          <li>Handling computational limits during K-Means on a 2000-entry dataset extended my work hours, reflecting challenges in large-scale cloud-based analytics for e-commerce firms.</li>
          <li>Addressing data privacy concerns, such as anonymizing customer income, added complexity, paralleling GDPR compliance issues in European marketing campaigns.</li>
          <li>Dealing with inconsistent data formats from multiple retail sources mimicked real-world issues in supply chain analytics, requiring custom preprocessing scripts.</li>
          <li>Managing stakeholder expectations for immediate results, similar to pressures in fast-paced retail sales forecasting, pushed me to optimize my workflow under tight deadlines.</li>
        </ul>
      </p>
    </div>

    <div class="tab-content" id="takeaways">
      <h2>Key Takeaways</h2>
      <p>
        <ul class="list-disc ml-6 space-y-2">
          <li>Effective preprocessing, like imputation and cleaning, is crucial for ethical clustering, a practice I now apply daily in data quality reviews before client presentations, similar to pre-processing in medical diagnostics.</li>
          <li>Diverse data audits and inclusive design, highlighted in class, are now part of my weekly routine, akin to diversity checks in hiring algorithms at tech companies.</li>
          <li>Visualizations enhance stakeholder communication, a skill I use daily in reports, mirroring their role in presenting sales trends to retail executives.</li>
          <li>Imputation as a morning routine ensures data integrity, a technique valuable in financial forecasting to handle missing market data.</li>
          <li>SMOTE and imbalance handling inspire fairness advocacy in study groups, paralleling efforts to balance representation in online ad targeting.</li>
          <li>Iterative refinement of K-Means taught validation skills, applicable to optimizing machine learning models in autonomous vehicle development.</li>
          <li>Collaborative problem-solving with peers improved my teamwork, reflecting real-world AI development in cross-functional teams at Google.</li>
          <li>Adapting to computational constraints enhanced my optimization skills, a practice useful in scaling AI models for large-scale social media analysis.</li>
        </ul>
      </p>
    </div>

    <div class="tab-content" id="reflection">
      <h2>Reflection</h2>
      <p>
        This artifact deepened my expertise in data preprocessing and ethical AI leadership, shaped by the "Navigating Human Bias" class. I mastered imputation for missing data, noise reduction with smoothing, and imbalance correction with SMOTE, skills honed through chatbot scenarios. In practice, I advocate for transparency in team projects, auditing datasets for underrepresented groups daily, much like ensuring fairness in loan approval algorithms. My goal was to excel in clustering while upholding ethics, achieved by integrating Shiyana’s feedback loops and scenario insights (e.g., Python code, metrics). The artifact produced four customer segments with enhanced fairness, validated iteratively. Chatbot feedback drove deeper exploration into MNAR data and tuning, documented for clarity, similar to refining models for climate prediction. Real-world applications, such as ethical AI in public policy, motivate me to pursue certifications in responsible AI, preparing me for leadership roles in global tech firms.
      </p>
    </div>

    <div class="tab-content" id="conclusion">
      <h2>Conclusion</h2>
      <p>
        The successful segmentation of customers into four groups demonstrates my advancing skills, grounded in ethical considerations. Diagrams like the overview diagram, elbow method graph, and cluster visualization enrich this artifact’s presentation, meeting all requirements. This work is now integral to my routine—morning fairness checks, lunchtime colleague discussions, and evening refinements—mirroring workflows in data-driven companies like Amazon. My commitment to ethical leadership grows, from team collaborations to personal learning, ensuring impact on diverse communities. Future plans include exploring hierarchical clustering for complex datasets, inspired by applications in genomic research.
      </p>
    </div>
  </div>

  <footer>
    <p>&copy; 2025 Shiyana Jayanesan Shylaja |
      <a href="https://sites.google.com/view/shiyana-portfolio/home" target="_blank">Artifact 1</a> |
      <a href="https://shiyana.github.io/Portfolio2/" target="_blank">Artifact 2</a> |
      <a href="https://shiyana.github.io/Portfolio3/" target="_blank">Artifact 3</a> |
      <a href="https://shiyana.github.io/Portfolio4/">Artifact 4</a>
    </p>
  </footer>
</body>
</html>
"""

# Save to file
file_path = "/mnt/data/Portfolio4_Complete.html"
Path(file_path).write_text(full_html_code)

file_path
