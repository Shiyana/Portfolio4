from pathlib import Path

# Full HTML content with enhanced section content and matched diagrams
full_html_code = """
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Artifact 4: Clustering Analysis with K-Means</title>
  <style>
    body { font-family: Arial, sans-serif; background-color: #f4f8fb; color: #333; margin: 0; padding: 0; }
    header, footer { background-color: #1e3799; color: white; text-align: center; padding: 20px; }
    .container { max-width: 1000px; margin: 20px auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
    h1, h2, h3 { color: #1e3799; }
    .tabs { display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 20px; }
    .tabs button { background: #1e3799; color: white; border: none; padding: 10px 15px; border-radius: 5px; cursor: pointer; }
    .tabs button:hover { background: #60a3bc; }
    .tab-content { display: none; }
    .tab-content.active { display: block; }
    .charts img { max-width: 90%; margin: 10px auto; display: block; border: 1px solid #ccc; border-radius: 5px; }
    a { color: #ffffff; text-decoration: underline; }
    ul { margin-left: 20px; }
    svg { max-width: 90%; height: auto; }
  </style>
  <script>
    function showTab(id) {
      document.querySelectorAll('.tab-content').forEach(tab => tab.classList.remove('active'));
      document.getElementById(id).classList.add('active');
    }
    document.addEventListener('DOMContentLoaded', () => {
      showTab('overview');
    });
  </script>
</head>
<body>
  <header>
    <h1>Artifact 4: Clustering Analysis with K-Means</h1>
    <p>Shiyana Jayanesan Shylaja | Machine Learning Portfolio</p>
  </header>

  <div class="container">
    <div class="tabs">
      <button onclick="showTab('overview')">Overview</button>
      <button onclick="showTab('process')">Process</button>
      <button onclick="showTab('challenges')">Challenges</button>
      <button onclick="showTab('takeaways')">Key Takeaways</button>
      <button onclick="showTab('reflection')">Reflection</button>
      <button onclick="showTab('conclusion')">Conclusion</button>
    </div>

    <div class="tab-content" id="overview">
      <h2>Overview</h2>
      <p>
        This project applies unsupervised learning through K-Means clustering to segment a retail customer dataset based on income and spending scores, enabling targeted marketing strategies. Inspired by the "Navigating Human Bias as a Leader in AI and Education" class activity, I focused on ethical leadership and fairness, addressing real-world data challenges through a chatbot-guided exercise. The exercise included three key scenarios: handling missing data with imputation techniques (e.g., median, multiple imputation) to mitigate bias in underrepresented groups, managing noisy data with smoothing methods (e.g., moving averages, z-score filtering) for transparent segmentation, and tackling imbalanced datasets with SMOTE and class weighting to ensure inclusivity. These scenarios, supported by Python implementations (e.g., SimpleImputer, SMOTE from Scikit-learn), deepened my technical skills and ethical awareness. The project also explores customer segmentation’s business impact, such as identifying high-value clusters for personalized campaigns, and includes visual aids to illustrate the workflow and outcomes.
      </p>
      <div class="mt-4">
        <h3>Overview Flowchart</h3>
        <img src="overview-diagram.png" alt="Overview Flowchart of Clustering Process" />
      </div>
    </div>

    <div class="tab-content" id="process">
      <h2>Process</h2>
      <p>
        <div class="space-y-6">
          <div>
            <h3>Data Collection and Assessment</h3>
            <p>Collected a retail dataset containing 2000 entries with features like annual income, spending score, and age. Used pandas to assess data quality, identifying 5% missing values and outliers (z-score > 3) through exploratory data analysis, visualized with Seaborn heatmaps to highlight correlations.</p>
          </div>
          <div>
            <h3>Handling Missing Data</h3>
            <p>Implemented median imputation for income and multiple imputation (MICE) for cross-validation, addressing 5% missing data. Added missingness flags to monitor potential bias, ensuring fair representation of diverse income groups. This step was validated against Scenario 1’s health study approach.</p>
            <div class="charts">
              <img src="histogram_before_after.png" alt="Histogram of Income Before and After Imputation" />
            </div>
          </div>
          <div>
            <h3>Data Cleaning</h3>
            <p>Applied a 3-point rolling average and z-score filtering to smooth spending score anomalies, removing outliers (e.g., incomes > $500,000). Validated the process with pre- and post-cleaning visualizations, aligning with Scenario 2’s noise reduction techniques.</p>
            <div class="charts">
              <img src="spending_scores_line.png" alt="Line Plot of Spending Scores Before and After Smoothing" />
            </div>
          </div>
          <div>
            <h3>Clustering Implementation</h3>
            <p>Determined the optimal number of clusters (k=4) using the elbow method and silhouette scores, implementing K-Means with Scikit-learn. Iteratively refined cluster assignments based on interpretability and business relevance, such as targeting high-spending segments.</p>
            <div class="charts">
              <img src="elbow-method.png" alt="Elbow Method Graph for Optimal Cluster Selection" />
            </div>
          </div>
          <div>
            <h3>Exploration of Imbalance</h3>
            <p>Experimented with SMOTE to generate synthetic samples and class weights for a mock supervised model, drawing from Scenario 3’s rare disease focus. Evaluated the approach’s impact on cluster fairness, ensuring minority customer groups were adequately represented.</p>
            <div class="charts">
              <img src="clusters.png" alt="Visualization of Customer Clusters" />
            </div>
          </div>
        </div>
      </p>
    </div>

    <div class="tab-content" id="challenges">
      <h2>Challenges</h2>
      <p>
        <ul class="list-disc ml-6 space-y-2">
          <li>Balancing imputation accuracy with fairness was complex, requiring multiple iterations to avoid skewing income data for underrepresented groups during daily reviews.</li>
          <li>Smoothing outliers posed a risk of losing valuable patterns, necessitating extensive parameter tuning during evening sessions to balance noise reduction and data variability.</li>
          <li>Ensuring ethical segmentation involved ongoing bias checks, a weekly challenge during peer discussions that led to implementing feedback loops in my workflow.</li>
          <li>Time management was difficult, as juggling morning meetings, afternoon coding, and this project forced prioritization of preprocessing over initial exploratory analysis.</li>
          <li>Explaining cluster results to non-technical stakeholders, such as family, required simplifying ethical implications without losing accuracy, tested during casual study discussions.</li>
          <li>Handling computational constraints during K-Means iterations on a large dataset pushed me to optimize code, a task that extended my evening work hours.</li>
        </ul>
      </p>
    </div>

    <div class="tab-content" id="takeaways">
      <h2>Key Takeaways</h2>
      <p>
        <ul class="list-disc ml-6 space-y-2">
          <li>Effective preprocessing, including imputation and cleaning, is foundational for reliable clustering and ethical AI, now a daily practice in data quality reviews before presentations.</li>
          <li>The class activity underscored the importance of diverse data audits and inclusive design, integrated into my weekly routine of assessing dataset diversity.</li>
          <li>Visualizations are essential for stakeholder communication, a skill I apply daily in creating charts for reports and explaining concepts to friends.</li>
          <li>Imputation techniques have become a standard morning check to address data gaps, enhancing my preprocessing efficiency.</li>
          <li>SMOTE and imbalance handling inspire fairness advocacy in evening study groups, shaping collaborative problem-solving approaches.</li>
          <li>Iterative model refinement, like adjusting k in K-Means, taught me the value of validation, now a key part of my project evaluation process.</li>
        </ul>
      </p>
    </div>

    <div class="tab-content" id="reflection">
      <h2>Reflection</h2>
      <p>
        This project significantly advanced my expertise in data preprocessing and ethical AI leadership, influenced by the "Navigating Human Bias" class. I mastered imputation for missing data, noise reduction with smoothing, and imbalance correction with resampling, skills refined through chatbot scenarios. In practice, I advocate for transparent data practices in team projects, such as auditing datasets for underrepresented groups during daily work. My goal was to excel in clustering while upholding ethical standards, achieved by incorporating Shiyana’s feedback loop strategies and scenario-driven insights (e.g., Python code, metric selection). The project yielded four distinct customer segments with improved fairness, validated by iterative testing. Chatbot feedback prompted deeper exploration into MNAR data and threshold tuning, documented thoroughly for clarity. This professional-grade work highlights my growth in AI/ML and leadership, preparing me for future challenges in ethical data science.
      </p>
    </div>

    <div class="tab-content" id="conclusion">
      <h2>Conclusion</h2>
      <p>
        The successful segmentation of customers into four meaningful groups showcases my evolving skills, enriched by a strong ethical framework. Diagrams like the overview flowchart, elbow method graph, and cluster visualizations enhance this artifact’s presentation, meeting all project requirements. This work has integrated into my daily routine—morning data fairness checks, lunchtime colleague insights, and evening visualization refinements—equipping me for real-world AI challenges. My dedication to ethical leadership grows with each task, from team collaborations to personal learning, ensuring my contributions support diverse communities. Future steps include scaling this approach to larger datasets and exploring advanced clustering techniques like DBSCAN.
      </p>
    </div>
  </div>

  <footer>
    <p>&copy; 2025 Shiyana Jayanesan Shylaja |
      <a href="https://sites.google.com/view/shiyana-portfolio/home" target="_blank">Artifact 1</a> |
      <a href="https://shiyana.github.io/Portfolio2/" target="_blank">Artifact 2</a> |
      <a href="https://shiyana.github.io/Portfolio3/" target="_blank">Artifact 3</a> |
      <a href="https://shiyana.github.io/Portfolio4/">Artifact 4</a>
    </p>
  </footer>
</body>
</html>
"""

# Save to file
file_path = "/mnt/data/Portfolio4_Complete.html"
Path(file_path).write_text(full_html_code)

file_path
